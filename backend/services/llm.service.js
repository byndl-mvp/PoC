const { openai, anthropic, MODEL_OPENAI, MODEL_ANTHROPIC } = require('../config/llm.config');

/**
 * Erweiterte LLM-Policy mit robuster Fehlerbehandlung
 */
async function llmWithPolicy(task, messages, options = {}) {
  // KOPIEREN SIE DIE GESAMTE FUNKTION aus server.js
  // Von Zeile ~85 bis ~250
  // ALLES was Sie in Ihrer Nachricht gezeigt haben
}

module.exports = {
  llmWithPolicy
};
